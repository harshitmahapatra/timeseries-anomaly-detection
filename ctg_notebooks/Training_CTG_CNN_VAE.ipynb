{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VAE for Anomaly Detection\n",
    "\n",
    "The goal is to train Variational Autoencoders for anomaly detection.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "ECG Heartbeat Categorization Dataset: https://www.kaggle.com/datasets/shayanfazeli/heartbeat?resource=download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch import Tensor, FloatTensor, nn\n",
    "from pandarallel import pandarallel\n",
    "from typing import Optional\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    Subset,\n",
    "    ConcatDataset,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import shutil\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from torchmetrics import Accuracy, ConfusionMatrix, AUROC, ROC\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup for reproducibility\n",
    "SEED_VALUE = 500\n",
    "pl.seed_everything(SEED_VALUE)\n",
    "\n",
    "\n",
    "# Constants\n",
    "WINDOW_LENGTH = timedelta(minutes=10)\n",
    "WINDOW_STRIDE = timedelta(minutes=10)\n",
    "PH_THRESHOLD = 7.05\n",
    "MAX_DATETIME_DIFFERENCE_CTG = timedelta(days=365)\n",
    "CALCULATED_Z_SCORE_PARAMS = [\n",
    "    1016201603,\n",
    "    138.06500900606565,\n",
    "    324618849082.29016,\n",
    "    1016201462,\n",
    "    21.75170609426872,\n",
    "    606363058472.4089,\n",
    "]\n",
    "Z_SCORE_OFFSET = 2\n",
    "MIN_MAX_PARAMS = [0, 240, 0, 127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Parallel Apply\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test time series dataset\n",
    "ecg_dataset = Path(\"../ecg/ptbdb_abnormal.csv\")\n",
    "df = pd.read_csv(ecg_dataset, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test time series dataset\n",
    "ecg_dataset_abnormal = Path(\"../ecg/ptbdb_abnormal.csv\")\n",
    "df_abnormal = pd.read_csv(ecg_dataset_abnormal, header=None)\n",
    "df_abnormal.head()\n",
    "ecg_row = df_abnormal.iloc[2]\n",
    "print(ecg_row.tail(1).values[0])\n",
    "ecg_row = ecg_row[:-1]\n",
    "print(ecg_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test time series\n",
    "# Generic function to visualize CTGs\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import timedelta\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def visualize_ecg(\n",
    "    ecg: List,\n",
    "    show_points: bool = False,\n",
    "):\n",
    "    fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "    if show_points:\n",
    "        mode = \"lines+markers\"\n",
    "    else:\n",
    "        mode = \"lines\"\n",
    "\n",
    "    marker = dict(color=\"#FFFFFF\", size=5, line=dict(color=\"black\", width=1))\n",
    "    ecg = go.Scatter(\n",
    "        x=[*range(len(ecg))],\n",
    "        y=ecg,\n",
    "        name=f\"ECG\",\n",
    "        mode=mode,\n",
    "        marker=marker,\n",
    "        line=dict(color=\"red\", width=2),\n",
    "    )\n",
    "    fig.append_trace(ecg, row=1, col=1)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_roc_curve(fpr, tpr, thresholds, filename: Path):\n",
    "    \"\"\"Plot and save the ROC curve.\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    fpr = fpr.cpu().numpy()\n",
    "    tpr = tpr.cpu().numpy()\n",
    "\n",
    "    ax.plot(fpr, tpr, \"o\")\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel(\"False Positive Labels (FPR)\")\n",
    "    ax.set_ylabel(\"True Positive Labels (TPR)\")\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "    fig.savefig(filename)\n",
    "    plt.clf()\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ecg = df.sample().values.flatten().tolist()\n",
    "fig = visualize_ecg(random_ecg)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    \"\"\"Class representing the ECG dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: Path):\n",
    "        self.data_dir = data_dir\n",
    "        self.normal_df = pd.read_csv(data_dir / \"ptbdb_normal.csv\", header=None)\n",
    "        self.normal_last_row = self.normal_df.shape[0] - 1\n",
    "        self.abnormal_df = pd.read_csv(data_dir / \"ptbdb_abnormal.csv\", header=None)\n",
    "        self.df = pd.concat([self.normal_df, self.abnormal_df])\n",
    "        self.df = self.df.reset_index()\n",
    "        self.df = self.df.drop(\"index\", axis=1)\n",
    "        self.df = self.df.rename(columns={int(f\"{len(df.columns)-1}\"): \"label\"})\n",
    "        self._targets = torch.tensor(self.df[\"label\"].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ecg_row = self.df.iloc[index]\n",
    "        label = ecg_row.tail(1).values[0]\n",
    "        ecg_row = ecg_row[:-1]\n",
    "        ecg = ecg_row.values.flatten().tolist()\n",
    "        ecg_tensor = torch.from_numpy(np.array([ecg])).float()\n",
    "        #         ecg_tensor = ecg_tensor.permute(1,0)\n",
    "        return ecg_tensor, label\n",
    "\n",
    "    @property\n",
    "    def normal_idx(self) -> Tensor:\n",
    "        return [*range(self.normal_last_row + 1)]\n",
    "\n",
    "    @property\n",
    "    def abnormal_idx(self) -> Tensor:\n",
    "        return [*range(self.normal_last_row + 1, self.df.shape[0])]\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> Tensor:\n",
    "        return self._targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_dataset = ECGDataset(data_dir=Path(\"/home/harshit/ecg-anomaly-detection/ecg/\"))\n",
    "ecg, label = ecg_dataset.__getitem__(0)\n",
    "print(ecg.shape)\n",
    "print(ecg)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Datamodule class to load the CTG dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: Path = Path(\"../ecg\"),\n",
    "        batch_size: int = 32,\n",
    "        split_seed: int = 50,\n",
    "        num_workers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        self.full_dataset = ECGDataset(\n",
    "            self.hparams.data_dir,\n",
    "        )\n",
    "        self.normal_dataset = Subset(self.full_dataset, self.full_dataset.normal_idx)\n",
    "        self.abnormal_dataset = Subset(\n",
    "            self.full_dataset, self.full_dataset.abnormal_idx\n",
    "        )\n",
    "\n",
    "        non_test_indexes, test_indexes = train_test_split(\n",
    "            np.arange(len(self.normal_dataset)),\n",
    "            test_size=0.20,\n",
    "            random_state=self.hparams.split_seed,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        self.data_test_normal = Subset(self.normal_dataset, test_indexes)\n",
    "        # Extract val samples from remaining\n",
    "        train_indexes, val_indexes = train_test_split(\n",
    "            non_test_indexes,\n",
    "            test_size=0.25,\n",
    "            random_state=self.hparams.split_seed,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Train and val datasets just containing normal samples\n",
    "        self.data_train = Subset(self.normal_dataset, train_indexes)\n",
    "\n",
    "        # Single batch experiment\n",
    "        #         random_single_batch_indexes = random.sample(sorted(train_indexes), self.hparams.batch_size)\n",
    "        #         self.random_single_batch = Subset(self.normal_dataset, random_single_batch_indexes)\n",
    "\n",
    "        self.data_val = Subset(self.normal_dataset, val_indexes)\n",
    "\n",
    "        # Test dataset containing just abnormal samples\n",
    "        self.data_test = ConcatDataset([self.data_test_normal, self.abnormal_dataset])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_train,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_val,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_test,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size=4096, hidden_size=1024, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        outputs, (hidden, cell) = self.lstm(x)\n",
    "        return (hidden, cell)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_size=4096, hidden_size=1024, output_size=4096, num_layers=2\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        output, (hidden, cell) = self.lstm(x, hidden)\n",
    "        prediction = self.fc(output)\n",
    "        prediction = self.sig(prediction)\n",
    "        return prediction, (hidden, cell)\n",
    "\n",
    "\n",
    "class ECG_LSTM_VAE(pl.LightningModule):\n",
    "    \"\"\"The class represneting the VAE model used for regression on CTGs.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        input_size: int, batch_size x sequence_length x input_dim\n",
    "        hidden_size: int, output size of LSTM AE\n",
    "        latent_size: int, latent z-layer size\n",
    "        num_lstm_layer: int, number of layers in LSTM\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # dimensions\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.input_size = config[\"input_size\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.latent_size = config[\"latent_size\"]\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.beta = config[\"beta\"]\n",
    "        self.save_images = config[\"save_images\"]\n",
    "        self.saved_images_path = config[\"saved_images_path\"]\n",
    "        self.anomaly_threshold = 0.01\n",
    "\n",
    "        # lstm ae\n",
    "        self.lstm_enc = Encoder(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "        )\n",
    "        self.lstm_dec = Decoder(\n",
    "            input_size=self.latent_size,\n",
    "            output_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "        )\n",
    "\n",
    "        self.fc21 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc22 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc3 = nn.Linear(self.latent_size, self.hidden_size)\n",
    "\n",
    "        # ROC curve\n",
    "        self.metrics = torch.nn.ModuleDict(\n",
    "            {\n",
    "                \"test_auc\": AUROC(num_classes=None, max_fpr=0.15),\n",
    "                \"test_roc\": ROC(num_classes=None),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def reparametize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        noise = torch.randn_like(std)\n",
    "\n",
    "        z = mu + noise * std\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feature_dim = x.shape\n",
    "\n",
    "        # encode input space to hidden space\n",
    "        enc_hidden = self.lstm_enc(x)\n",
    "        enc_h = enc_hidden[0].view(batch_size, self.hidden_size)\n",
    "\n",
    "        # extract latent variable z(hidden space to latent space)\n",
    "        mean = self.fc21(enc_h)\n",
    "        logvar = self.fc22(enc_h)\n",
    "        z = self.reparametize(mean, logvar)  # batch_size x latent_size\n",
    "\n",
    "        # decode latent space to input space\n",
    "        z = z.repeat(1, seq_len, 1)\n",
    "        z = z.view(batch_size, seq_len, self.latent_size)\n",
    "        reconstruct_output, hidden = self.lstm_dec(z, enc_hidden)\n",
    "\n",
    "        x_hat = reconstruct_output\n",
    "        return mean, logvar, x_hat\n",
    "\n",
    "    def loss_function(self, *args, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "        pairwise = args[4]\n",
    "\n",
    "        if pairwise:\n",
    "            recons_loss = F.mse_loss(recons, input, reduction=\"none\")\n",
    "            kld_loss = -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1)\n",
    "        else:\n",
    "            recons_loss = F.mse_loss(recons, input)\n",
    "            kld_loss = torch.sum(\n",
    "                -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n",
    "            )\n",
    "\n",
    "        loss = recons_loss + (self.beta * kld_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"Reconstruction_Loss\": recons_loss,\n",
    "            \"KLD\": -kld_loss,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=(self.lr))\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        self.log(\n",
    "            \"train_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"kld_loss\", loss_dict[\"KLD\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"recon_loss\",\n",
    "            loss_dict[\"Reconstruction_Loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss_dict\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        self.log(\n",
    "            \"val_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_kld_loss\", loss_dict[\"KLD\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_recon_loss\",\n",
    "            loss_dict[\"Reconstruction_Loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"reconstructed\": x_out, \"original\": x, \"loss\": loss_dict[\"loss\"]}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if not self.save_images:\n",
    "            return\n",
    "        if not os.path.exists(self.saved_images_path):\n",
    "            os.makedirs(self.saved_images_path)\n",
    "        recon = torch.cat([tmp[\"reconstructed\"] for tmp in outputs])\n",
    "        orig = torch.cat([tmp[\"original\"] for tmp in outputs])\n",
    "        orig_saved_filename = self.save_signal_figure(orig[0], \"original\")\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, orig_saved_filename)\n",
    "        recon_saved_filename = self.save_signal_figure(recon[0], \"reconstructed\")\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, recon_saved_filename)\n",
    "\n",
    "    def save_signal_figure(self, signal_tensor, name):\n",
    "        signal_tensor = signal_tensor.permute(1, 0)\n",
    "        ecg = signal_tensor[0].cpu().detach().numpy()\n",
    "        # toco_tensor = signal_tensor[1].cpu().detach().numpy()\n",
    "        fig = visualize_ecg(ecg)\n",
    "        saved_filename = (\n",
    "            f\"{self.saved_images_path}/{name}_epoch_{self.current_epoch+1}.png\"\n",
    "        )\n",
    "        fig.write_image(saved_filename)\n",
    "        return saved_filename\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ctgs, labels = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        return {\"mu\": mu, \"log_var\": log_var, \"loss\": loss_dict[\"loss\"]}\n",
    "\n",
    "    def test_epoch_end(self, batch, batch_idx):\n",
    "        ctgs, labels = batch\n",
    "        mu, log_var, output = self(ctgs)\n",
    "        return {\"mu\": mu, \"log_var\": log_var, \"output\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN AE model\n",
    "class ECGAE(pl.LightningModule):\n",
    "    \"\"\"The class represneting the VAE model used for regression on CTGs.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        input_size: int, batch_size x sequence_length x input_dim\n",
    "        hidden_size: int, output size of LSTM AE\n",
    "        latent_size: int, latent z-layer size\n",
    "        num_lstm_layer: int, number of layers in LSTM\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # dimensions\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.save_images = config[\"save_images\"]\n",
    "        self.saved_images_path = config[\"saved_images_path\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(188, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 8),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 188),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feature_dim = x.shape\n",
    "        x = x.view(batch_size, seq_len)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def loss_function(self, *args, **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "\n",
    "        batch_size, seq_len, feature_dim = input.shape\n",
    "        input = input.view(batch_size, seq_len)\n",
    "\n",
    "        loss = F.mse_loss(recons, input)\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=(self.lr))\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x)\n",
    "        self.log(\n",
    "            \"train_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        return loss_dict\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x)\n",
    "        self.log(\n",
    "            \"val_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        return {\n",
    "            \"reconstructed\": x_out,\n",
    "            \"original\": x.squeeze(),\n",
    "            \"loss\": loss_dict[\"loss\"],\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if not self.save_images:\n",
    "            return\n",
    "        if not os.path.exists(self.saved_images_path):\n",
    "            os.makedirs(self.saved_images_path)\n",
    "        recon = torch.cat([tmp[\"reconstructed\"] for tmp in outputs])\n",
    "        orig = torch.cat([tmp[\"original\"] for tmp in outputs])\n",
    "        if self.current_epoch == 0:\n",
    "            orig_saved_filename = self.save_signal_figure(orig[0], \"original\")\n",
    "            self.logger.experiment.log_artifact(self.logger.run_id, orig_saved_filename)\n",
    "        recon_saved_filename = self.save_signal_figure(recon[0], \"reconstructed\")\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, recon_saved_filename)\n",
    "\n",
    "    def save_signal_figure(self, signal_tensor, name):\n",
    "        ecg = signal_tensor.cpu().detach().numpy()\n",
    "        # toco_tensor = signal_tensor[1].cpu().detach().numpy()\n",
    "        fig = visualize_ecg(ecg)\n",
    "        saved_filename = (\n",
    "            f\"{self.saved_images_path}/{name}_epoch_{self.current_epoch+1}.png\"\n",
    "        )\n",
    "        fig.write_image(saved_filename)\n",
    "        return saved_filename\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ctgs, labels = batch\n",
    "        mu, log_var, output = self(ctgs)\n",
    "        return {\"mu\": mu, \"log_var\": log_var, \"output\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_VAE(pl.LightningModule):\n",
    "    \"\"\"The class represneting the VAE model used for regression on CTGs.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        input_size: int, batch_size x sequence_length x input_dim\n",
    "        hidden_size: int, output size of LSTM AE\n",
    "        latent_size: int, latent z-layer size\n",
    "        num_lstm_layer: int, number of layers in LSTM\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # dimensions\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.input_size = config[\"input_size\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.latent_size = config[\"latent_size\"]\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.beta = config[\"beta\"]\n",
    "        self.save_images = config[\"save_images\"]\n",
    "        self.saved_images_path = config[\"saved_images_path\"]\n",
    "\n",
    "        # normal vae\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(188, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, self.hidden_size),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 188),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.fc21 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc22 = nn.Linear(self.hidden_size, self.latent_size)\n",
    "        self.fc3 = nn.Linear(self.latent_size, self.hidden_size)\n",
    "\n",
    "    def reparametize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        noise = torch.randn_like(std)\n",
    "\n",
    "        z = mu + noise * std\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feature_dim = x.shape\n",
    "        x = x.squeeze()\n",
    "\n",
    "        # encode input space to hidden space\n",
    "        enc = self.encoder(x)\n",
    "\n",
    "        # extract latent variable z(hidden space to latent space)\n",
    "        mean = self.fc21(enc)\n",
    "        logvar = self.fc22(enc)\n",
    "        z = self.reparametize(mean, logvar)  # batch_size x latent_size\n",
    "\n",
    "        # decode latent space to input space\n",
    "        z = self.fc3(z)\n",
    "        reconstruct_output = self.decoder(z)\n",
    "\n",
    "        x_hat = reconstruct_output\n",
    "        return mean, logvar, x_hat\n",
    "\n",
    "    def loss_function(self, *args, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        batch_size, seq_len, feature_dim = input.shape\n",
    "        input = input.view(batch_size, seq_len)\n",
    "\n",
    "        recons_loss = F.mse_loss(recons, input)\n",
    "\n",
    "        kld_loss = torch.mean(\n",
    "            -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n",
    "        )\n",
    "\n",
    "        loss = recons_loss + (self.beta * kld_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"Reconstruction_Loss\": recons_loss,\n",
    "            \"KLD\": -kld_loss,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=(self.lr))\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        self.log(\n",
    "            \"train_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"kld_loss\", loss_dict[\"KLD\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"recon_loss\",\n",
    "            loss_dict[\"Reconstruction_Loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss_dict\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        self.log(\n",
    "            \"val_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_kld_loss\", loss_dict[\"KLD\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_recon_loss\",\n",
    "            loss_dict[\"Reconstruction_Loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\n",
    "            \"reconstructed\": x_out,\n",
    "            \"original\": x.squeeze(),\n",
    "            \"loss\": loss_dict[\"loss\"],\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if not self.save_images:\n",
    "            return\n",
    "        if not os.path.exists(self.saved_images_path):\n",
    "            os.makedirs(self.saved_images_path)\n",
    "        recon = torch.cat([tmp[\"reconstructed\"] for tmp in outputs])\n",
    "        orig = torch.cat([tmp[\"original\"] for tmp in outputs])\n",
    "        if self.current_epoch == 0:\n",
    "            orig_saved_filename = self.save_signal_figure(orig[0], \"original\")\n",
    "            self.logger.experiment.log_artifact(self.logger.run_id, orig_saved_filename)\n",
    "        recon_saved_filename = self.save_signal_figure(recon[0], \"reconstructed\")\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, recon_saved_filename)\n",
    "\n",
    "    def save_signal_figure(self, signal_tensor, name):\n",
    "        ecg = signal_tensor.cpu().detach().numpy()\n",
    "        # toco_tensor = signal_tensor[1].cpu().detach().numpy()\n",
    "        fig = visualize_ecg(ecg)\n",
    "        saved_filename = (\n",
    "            f\"{self.saved_images_path}/{name}_epoch_{self.current_epoch+1}.png\"\n",
    "        )\n",
    "        fig.write_image(saved_filename)\n",
    "        return saved_filename\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ctgs, labels = batch\n",
    "        mu, log_var, output = self(ctgs)\n",
    "        return {\"mu\": mu, \"log_var\": log_var, \"output\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CNN_VAE(pl.LightningModule):\n",
    "    \"\"\"The class represneting the VAE model used for regression on CTGs.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        input_size: int, batch_size x sequence_length x input_dim\n",
    "        hidden_size: int, output size of LSTM AE\n",
    "        latent_size: int, latent z-layer size\n",
    "        num_lstm_layer: int, number of layers in LSTM\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # dimensions\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.input_size = config[\"input_size\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.latent_size = config[\"latent_size\"]\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.beta = config[\"beta\"]\n",
    "        self.save_images = config[\"save_images\"]\n",
    "        self.saved_images_path = config[\"saved_images_path\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "\n",
    "        # ROC curve\n",
    "        self.metrics = torch.nn.ModuleDict(\n",
    "            {\n",
    "                \"test_auc\": AUROC(task=\"binary\", num_classes=None, max_fpr=0.15),\n",
    "                \"test_roc\": ROC(task=\"binary\", num_classes=None),\n",
    "                \"test_roc_kld\": ROC(task=\"binary\", num_classes=None),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        modules = []\n",
    "        hidden_dims = [8, 16, 32, 64, 128]\n",
    "        latent_dim = self.latent_size\n",
    "\n",
    "        # Build Encoder\n",
    "        in_channels = 1\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=h_dim,\n",
    "                        kernel_size=3,\n",
    "                        stride=2,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1] * 6, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1] * 6, latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 6)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose1d(\n",
    "                        hidden_dims[i],\n",
    "                        hidden_dims[i + 1],\n",
    "                        kernel_size=3,\n",
    "                        stride=2,\n",
    "                        padding=1,\n",
    "                        output_padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.ConvTranspose1d(\n",
    "                hidden_dims[-1],\n",
    "                hidden_dims[-1],\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm1d(hidden_dims[-1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(hidden_dims[-1], out_channels=1, kernel_size=6, padding=0),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def reparametize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        noise = torch.randn_like(std)\n",
    "\n",
    "        z = mu + noise * std\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feature_dim = x.shape\n",
    "\n",
    "        # encode input space to hidden space\n",
    "        enc = self.encoder(x)\n",
    "        self.log(\n",
    "            \"enc_weight\",\n",
    "            self.encoder[4][0].weight[0][0][0],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        enc = torch.flatten(enc, start_dim=1)\n",
    "\n",
    "        # extract latent variable z(hidden space to latent space)\n",
    "        mean = self.fc_mu(enc)\n",
    "        logvar = self.fc_var(enc)\n",
    "\n",
    "        self.log(\n",
    "            \"mean_sample_0\", mean.data[0][0], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"logvar_sample_0\",\n",
    "            logvar.data[0][0],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        z = self.reparametize(mean, logvar)  # batch_size x latent_size\n",
    "\n",
    "        # decode latent space to input space\n",
    "        z = self.decoder_input(z)\n",
    "        self.log(\n",
    "            \"dec_input_weight\",\n",
    "            self.decoder_input.weight[0][0],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        z = z.view(-1, 128, 6)\n",
    "        out = self.decoder(z)\n",
    "\n",
    "        self.log(\n",
    "            \"dec_weight\",\n",
    "            self.decoder[0][0].weight[0][0][0],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        reconstruct_output = self.final_layer(out)\n",
    "\n",
    "        x_hat = reconstruct_output\n",
    "        return mean, logvar, x_hat\n",
    "\n",
    "    def loss_function(self, *args, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        mu = args[2]\n",
    "        log_var = args[3]\n",
    "        test = args[4]\n",
    "\n",
    "        if test:\n",
    "            loss = nn.BCELoss(reduction=\"none\")\n",
    "            #             recons_loss = torch.mean(torch.squeeze(loss(recons, input)),dim=1)\n",
    "            recons_loss = torch.squeeze(\n",
    "                torch.mean(F.mse_loss(recons, input, reduction=\"none\"), dim=2)\n",
    "            )\n",
    "            kld_loss = -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1)\n",
    "        else:\n",
    "            #             recons_loss = F.binary_cross_entropy(recons, input, reduction='sum')\n",
    "            recons_loss = torch.sum(\n",
    "                torch.squeeze(\n",
    "                    torch.sum(F.mse_loss(recons, input, reduction=\"none\"), dim=2)\n",
    "                )\n",
    "            )\n",
    "            kld_loss = torch.mean(\n",
    "                -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n",
    "            )\n",
    "\n",
    "        # To account for minibatches\n",
    "        kld_weight = input.shape[0] / self.batch_size\n",
    "\n",
    "        ## KL Cyclic Annealing\n",
    "        beta = (self.current_epoch % 10) / 10\n",
    "        if test:\n",
    "            beta = 1\n",
    "\n",
    "        # Final loss\n",
    "        loss = recons_loss + (self.beta * kld_weight * kld_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"Reconstruction_Loss\": recons_loss,\n",
    "            \"KLD\": -kld_loss,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=(self.lr))\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var, False)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var, False)\n",
    "        self.log(\n",
    "            \"train_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"kld_loss\", loss_dict[\"KLD\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"recon_loss\",\n",
    "            loss_dict[\"Reconstruction_Loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return loss_dict\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var, False)\n",
    "        self.log(\n",
    "            \"val_loss\", loss_dict[\"loss\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_kld_loss\", loss_dict[\"KLD\"], on_step=True, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_recon_loss\",\n",
    "            loss_dict[\"Reconstruction_Loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\"reconstructed\": x_out, \"original\": x, \"loss\": loss_dict[\"loss\"]}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if not self.save_images:\n",
    "            return\n",
    "        if not os.path.exists(self.saved_images_path):\n",
    "            os.makedirs(self.saved_images_path)\n",
    "        recon = torch.cat([tmp[\"reconstructed\"] for tmp in outputs])\n",
    "        orig = torch.cat([tmp[\"original\"] for tmp in outputs])\n",
    "        if self.current_epoch == 0:\n",
    "            orig_saved_filename = self.save_signal_figure(orig[200], \"original\")\n",
    "            self.logger.experiment.log_artifact(self.logger.run_id, orig_saved_filename)\n",
    "        recon_saved_filename = self.save_signal_figure(recon[200], \"reconstructed\")\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, recon_saved_filename)\n",
    "\n",
    "    def save_signal_figure(self, signal_tensor, name):\n",
    "        ecg = signal_tensor[0].cpu().detach().numpy()\n",
    "        fig = visualize_ecg(ecg)\n",
    "        saved_filename = (\n",
    "            f\"{self.saved_images_path}/{name}_epoch_{self.current_epoch+1}.png\"\n",
    "        )\n",
    "        fig.write_image(saved_filename)\n",
    "        return saved_filename\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ctgs, labels = batch\n",
    "        mu, log_var, output = self(ctgs)\n",
    "        return {\"mu\": mu, \"log_var\": log_var, \"output\": output}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, labels = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var, True)\n",
    "        loss = loss_dict[\"loss\"]\n",
    "        return {\n",
    "            \"reconstructed\": x_out,\n",
    "            \"original\": x,\n",
    "            \"labels\": labels,\n",
    "            \"loss\": loss_dict[\"loss\"],\n",
    "            \"recon_loss\": loss_dict[\"Reconstruction_Loss\"],\n",
    "            \"kld_loss\": loss_dict[\"KLD\"],\n",
    "        }\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        if not self.save_images:\n",
    "            return\n",
    "        if not os.path.exists(self.saved_images_path):\n",
    "            os.makedirs(self.saved_images_path)\n",
    "        recon = torch.cat([tmp[\"reconstructed\"] for tmp in outputs])\n",
    "        orig = torch.cat([tmp[\"original\"] for tmp in outputs])\n",
    "        labels = torch.cat([tmp[\"labels\"] for tmp in outputs])\n",
    "        loss = torch.cat([tmp[\"loss\"] for tmp in outputs])\n",
    "\n",
    "        recon_loss = torch.cat([tmp[\"recon_loss\"] for tmp in outputs])\n",
    "        recon_loss = (recon_loss - recon_loss.min()) / (\n",
    "            recon_loss.max() - recon_loss.min()\n",
    "        )\n",
    "\n",
    "        labels = labels.type(torch.int64)\n",
    "\n",
    "        self.metrics[\"test_auc\"](recon_loss, labels)\n",
    "        self.metrics[\"test_roc\"](recon_loss, labels)\n",
    "\n",
    "        fpr, tpr, thresholds = self.metrics[\"test_roc\"].compute()\n",
    "\n",
    "        self.log(\n",
    "            \"test_auc\", self.metrics[\"test_auc\"](recon_loss, labels), prog_bar=True\n",
    "        )\n",
    "\n",
    "        plot_filepath = Path(f\"test_roc.png\")\n",
    "        saved_filename = create_and_save_roc_curve(fpr, tpr, thresholds, plot_filepath)\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, saved_filename)\n",
    "        self.logger.experiment.log_artifact(self.logger.run_id, saved_filename)\n",
    "        plot_filepath.unlink()\n",
    "\n",
    "\n",
    "#         fpr, tpr, thresholds = self.metrics[\"test_roc_kld\"].compute()\n",
    "#         plot_filepath = Path(f\"test_roc_kld.png\")\n",
    "#         saved_filename = create_and_save_roc_curve(fpr, tpr, thresholds, plot_filepath)\n",
    "#         self.logger.experiment.log_artifact(self.logger.run_id, saved_filename)\n",
    "#         self.logger.experiment.log_artifact(self.logger.run_id, saved_filename)\n",
    "#         plot_filepath.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(config, num_epochs=20):\n",
    "    \"\"\"Train the CTGCNN model given the hyperparameters as config and the number of epochs.\n",
    "    The tune flag is used to specify if the training is standalone or part of a hyperparameter optimization process.\n",
    "    The k_fold flag is used to specify if the training should be done as K fold cross validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Clear out the previous models\n",
    "    models_folder = Path(f\"../models/\")\n",
    "\n",
    "    shutil.rmtree(models_folder)\n",
    "    models_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    mlflow_runs_folder = Path(\"../mlruns\")\n",
    "    mlflow_runs_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=models_folder,\n",
    "        filename=\"vae\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "\n",
    "    callbacks.append(checkpoint_callback)\n",
    "    #     callbacks.append(early_stopping_callback)\n",
    "\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=\"ecg_vae\",\n",
    "        tracking_uri=mlflow_runs_folder.absolute().as_uri(),\n",
    "    )\n",
    "    ecg_datamodule = ECGDataModule(\n",
    "        data_dir=Path(\"/home/harshit/ecg-anomaly-detection/ecg/\"),\n",
    "        split_seed=SEED_VALUE,\n",
    "        num_workers=16,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "    )\n",
    "    ecg_datamodule.setup()\n",
    "    ecg_model = ECG_CNN_VAE(config)\n",
    "    trainer = pl.Trainer(\n",
    "        logger=mlf_logger,\n",
    "        max_epochs=num_epochs,\n",
    "        callbacks=callbacks,\n",
    "        num_sanity_val_steps=0,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        #         gradient_clip_val=0.5,\n",
    "        #         gradient_clip_algorithm=\"value\",\n",
    "    )\n",
    "    trainer.fit(model=ecg_model, datamodule=ecg_datamodule)\n",
    "    trainer.test(model=ecg_model, datamodule=ecg_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "config = {\n",
    "    \"beta\": 0.1,\n",
    "    \"lr\": 1e-4,\n",
    "    \"save_images\": True,\n",
    "    \"saved_images_path\": \"plots\",\n",
    "    \"input_size\": 1,\n",
    "    \"hidden_size\": 4,\n",
    "    \"latent_size\": 4,\n",
    "    \"num_layers\": 1,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "model = ECG_CNN_VAE(config)\n",
    "summary(model, input_size=(32, 1, 187))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try training the model with some hyperparameters.\n",
    "config = {\n",
    "    \"beta\": 0.1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"save_images\": True,\n",
    "    \"saved_images_path\": \"plots\",\n",
    "    \"input_size\": 1,\n",
    "    \"hidden_size\": 8,\n",
    "    \"latent_size\": 8,\n",
    "    \"num_layers\": 1,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "train_model_with_hyperparams(config=config, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the accuracy of the model\n",
    "\n",
    "\n",
    "def test_latest_model(config, num_epochs):\n",
    "    mlflow_runs_folder = Path(\"../mlruns\")\n",
    "    mlflow_runs_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=\"ecg_vae\",\n",
    "        tracking_uri=mlflow_runs_folder.absolute().as_uri(),\n",
    "    )\n",
    "    ecg_datamodule = ECGDataModule(\n",
    "        data_dir=Path(\"/home/harshit/ecg-anomaly-detection/ecg/\"),\n",
    "        split_seed=SEED_VALUE,\n",
    "        num_workers=16,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "    )\n",
    "    ecg_datamodule.setup()\n",
    "    ecg_model = ECG_CNN_VAE(config)\n",
    "    trainer = pl.Trainer(\n",
    "        logger=mlf_logger,\n",
    "        max_epochs=num_epochs,\n",
    "        num_sanity_val_steps=0,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        #         gradient_clip_val=0.5,\n",
    "        #         gradient_clip_algorithm=\"value\",\n",
    "    )\n",
    "    trainer.test(\n",
    "        model=ecg_model, datamodule=ecg_datamodule, ckpt_path=\"../models/vae.ckpt\"\n",
    "    )\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"beta\": 0.1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"save_images\": True,\n",
    "    \"saved_images_path\": \"plots\",\n",
    "    \"input_size\": 1,\n",
    "    \"hidden_size\": 8,\n",
    "    \"latent_size\": 8,\n",
    "    \"num_layers\": 1,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "test_latest_model(config, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a series of models\n",
    "from typing import List\n",
    "\n",
    "config = {\n",
    "    \"beta\": 0.1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"save_images\": True,\n",
    "    \"saved_images_path\": \"plots\",\n",
    "    \"input_size\": 1,\n",
    "    \"hidden_size\": 8,\n",
    "    \"latent_size\": 8,\n",
    "    \"num_layers\": 1,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "ecg_model = ECG_CNN_VAE(config)\n",
    "model = ECG_CNN_VAE.load_from_checkpoint(\"../models/vae.ckpt\", config=config)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def visualize_long_sample(\n",
    "    samples: List,\n",
    "    predictions: List,\n",
    "    means: List,\n",
    "    sigmas: List,\n",
    "    show_points: bool = False,\n",
    "):\n",
    "    single_ecg_sample, _ = samples[0]\n",
    "\n",
    "    ecgs = [ecg for ecg, _ in samples]\n",
    "    ecgs = [item for sublist in ecgs for item in sublist]\n",
    "    ecgs = [item for sublist in ecgs for item in sublist]\n",
    "\n",
    "    labels = [np.ones(len(single_ecg_sample.data[0])) * label for _, label in samples]\n",
    "    labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "    preds = [np.ones(len(single_ecg_sample.data[0])) * pred for pred in predictions]\n",
    "    preds = [item for sublist in preds for item in sublist]\n",
    "\n",
    "    mus = []\n",
    "    for sample_means in means:\n",
    "        sample_mu = []\n",
    "        for mean in sample_means:\n",
    "            sample_mu.append(np.ones(len(single_ecg_sample.data[0])) * mean)\n",
    "        mus.append(sample_mu)\n",
    "\n",
    "    stds = []\n",
    "    for sample_sigmas in sigmas:\n",
    "        sample_std = []\n",
    "        for sigma in sample_sigmas:\n",
    "            sample_std.append(np.ones(len(single_ecg_sample.data[0])) * sigma)\n",
    "        stds.append(sample_std)\n",
    "\n",
    "    fig = make_subplots(rows=11, cols=1, shared_xaxes=True)\n",
    "\n",
    "    if show_points:\n",
    "        mode = \"lines+markers\"\n",
    "    else:\n",
    "        mode = \"lines\"\n",
    "\n",
    "    marker = dict(color=\"#FFFFFF\", size=5, line=dict(color=\"black\", width=1))\n",
    "    ecg = go.Scatter(\n",
    "        x=[*range(len(ecgs))],\n",
    "        y=ecgs,\n",
    "        name=f\"ECG\",\n",
    "        mode=mode,\n",
    "        marker=marker,\n",
    "        line=dict(color=\"red\", width=2),\n",
    "    )\n",
    "    pred = go.Scatter(\n",
    "        x=[*range(len(labels))],\n",
    "        y=preds,\n",
    "        name=f\"Prediction\",\n",
    "        mode=mode,\n",
    "        marker=marker,\n",
    "        line=dict(color=\"blue\", width=2),\n",
    "    )\n",
    "    label = go.Scatter(\n",
    "        x=[*range(len(labels))],\n",
    "        y=labels,\n",
    "        name=f\"Label\",\n",
    "        mode=mode,\n",
    "        marker=marker,\n",
    "        line=dict(color=\"orange\", width=2),\n",
    "    )\n",
    "\n",
    "    fig.append_trace(ecg, row=1, col=1)\n",
    "    fig.append_trace(pred, row=2, col=1)\n",
    "    fig.append_trace(label, row=3, col=1)\n",
    "\n",
    "    for distribution in np.arange(0, 8):\n",
    "        dist_mean = [mu[distribution] for mu in mus]\n",
    "        dist_mean = [item for sublist in dist_mean for item in sublist]\n",
    "\n",
    "        dist_std = [std[distribution] for std in stds]\n",
    "        dist_std = [item for sublist in dist_std for item in sublist]\n",
    "\n",
    "        dist_mean_upper = [(mean + abs(std)) for mean, std in zip(dist_mean, dist_std)]\n",
    "        dist_mean_lower = [(mean - abs(std)) for mean, std in zip(dist_mean, dist_std)]\n",
    "\n",
    "        mean_trace = go.Scatter(\n",
    "            x=[*range(len(labels))],\n",
    "            y=dist_mean,\n",
    "            name=f\"Latent_Var_{distribution+1}\",\n",
    "            mode=mode,\n",
    "            marker=marker,\n",
    "            line=dict(color=\"black\", width=2),\n",
    "        )\n",
    "        mean_trace_upper = go.Scatter(\n",
    "            x=[*range(len(labels))],\n",
    "            y=dist_mean_upper,\n",
    "            name=f\"Latent_Var_{distribution+1}_upper\",\n",
    "            mode=mode,\n",
    "            marker=marker,\n",
    "            line=dict(color=\"firebrick\", width=2, dash=\"dash\"),\n",
    "        )\n",
    "        mean_trace_lower = go.Scatter(\n",
    "            x=[*range(len(labels))],\n",
    "            y=dist_mean_lower,\n",
    "            name=f\"Latent_Var_{distribution+1}_lower\",\n",
    "            mode=mode,\n",
    "            marker=marker,\n",
    "            line=dict(color=\"darkgreen\", width=2, dash=\"dash\"),\n",
    "        )\n",
    "        fig.append_trace(mean_trace, row=3 + distribution + 1, col=1)\n",
    "        fig.append_trace(mean_trace_upper, row=3 + distribution + 1, col=1)\n",
    "        fig.append_trace(mean_trace_lower, row=3 + distribution + 1, col=1)\n",
    "\n",
    "    fig = fig.update_layout(width=4000, height=2200)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def generate_long_data_sample(\n",
    "    no_of_segments: int = 20, no_of_abnormal_segments: int = 6\n",
    "):\n",
    "    if no_of_abnormal_segments > no_of_segments:\n",
    "        raise ValueError(\n",
    "            \"No of abnormal segments must be less than the total no of segments.\"\n",
    "        )\n",
    "\n",
    "    no_of_normal_segments = no_of_segments - no_of_abnormal_segments\n",
    "\n",
    "    full_dataset = ECGDataset(data_dir=Path(\"/home/harshit/ecg-anomaly-detection/ecg\"))\n",
    "\n",
    "    normal_dataset = Subset(full_dataset, full_dataset.normal_idx)\n",
    "    abnormal_dataset = Subset(full_dataset, full_dataset.abnormal_idx)\n",
    "\n",
    "    normal_indexes = random.sample(\n",
    "        sorted(full_dataset.normal_idx), no_of_normal_segments\n",
    "    )\n",
    "    abnormal_indexes = random.sample(\n",
    "        sorted(full_dataset.abnormal_idx), no_of_abnormal_segments\n",
    "    )\n",
    "\n",
    "    normal_samples = [\n",
    "        full_dataset.__getitem__(normal_index) for normal_index in normal_indexes\n",
    "    ]\n",
    "    abnormal_samples = [\n",
    "        full_dataset.__getitem__(abnormal_index) for abnormal_index in abnormal_indexes\n",
    "    ]\n",
    "\n",
    "    samples = normal_samples + abnormal_samples\n",
    "\n",
    "    random.shuffle(samples)\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def get_prediction_for_ecg(ecg):\n",
    "    ecg = ecg.view(1, 1, 187)\n",
    "    mean, logvar, x_hat = model(ecg)\n",
    "    loss_dict = model.loss_function(x_hat, ecg, mean, logvar, True)\n",
    "    sigma = torch.abs(torch.exp(0.5 * logvar))\n",
    "\n",
    "    return loss_dict[\"Reconstruction_Loss\"], mean, sigma\n",
    "\n",
    "\n",
    "samples = generate_long_data_sample()\n",
    "outputs = [get_prediction_for_ecg(sample) for sample, _ in samples]\n",
    "\n",
    "predictions = [recon_loss.detach().cpu().numpy() for recon_loss, _, _ in outputs]\n",
    "means = [torch.squeeze(mean).detach().cpu().numpy() for _, mean, _ in outputs]\n",
    "sigmas = [torch.squeeze(sigma).detach().cpu().numpy() for _, sigma, _ in outputs]\n",
    "\n",
    "visualize_long_sample(\n",
    "    samples=samples, predictions=predictions, means=means, sigmas=sigmas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a710e520c235fc9a3ea75d114f992a279dedd3d542754d1b02db1fedfa5a3db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
