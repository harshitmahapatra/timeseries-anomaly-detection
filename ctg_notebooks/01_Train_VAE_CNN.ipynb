{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VAE CNN\n",
    "The goal is to train Variational Autoencoder containing Convolutional layers, that takes in valid sequences from the dataset.\n",
    "\n",
    "### Dataset Checkpoint Input\n",
    "- extracted-segments\n",
    "\n",
    "## Input Parameters\n",
    "* WINDOW_LENGTH: The length of the sliding window moved over the valid input segments to extract training data.\n",
    "* STRIDE: The stride of the sliding window.\n",
    "* PH_THRESHOLD: The threshold below which a CTG is considered to be associated with an abnormal birth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch import Tensor, nn\n",
    "from pandarallel import pandarallel\n",
    "from typing import Optional\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    "    Subset,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import shutil\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from datetime import timedelta, datetime\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup for reproducibility\n",
    "SEED_VALUE = 500\n",
    "pl.seed_everything(SEED_VALUE)\n",
    "\n",
    "# Constants\n",
    "PH_THRESHOLD = 7.05\n",
    "MAX_DATETIME_DIFFERENCE_CTG = timedelta(days=270)\n",
    "\n",
    "# Initialize Parallel Apply\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "# Visualization function for CTG\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from ctg_common import visualize_ctg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../ctg-data/final-ctg-dataset\")\n",
    "expanded_outcome = pd.read_parquet(data_dir / \"outcome_expanded.parquet\")\n",
    "expanded_outcome.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTGDataset(Dataset):\n",
    "    \"\"\"Class representing the CTG dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: Path,\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        outcomes = pd.read_parquet(data_dir / \"outcome_expanded.parquet\")\n",
    "        outcomes = outcomes[outcomes[\"no_of_points\"] > 2200]\n",
    "        outcomes = outcomes[outcomes[\"no_of_points\"] <= 2400]\n",
    "        self.outcomes = outcomes\n",
    "        self.outcomes[\"label\"] = (self.outcomes[\"ns_art_ph\"] < PH_THRESHOLD).astype(int)\n",
    "        self.outcomes = self.outcomes[self.outcomes[\"ns_art_ph\"] >= PH_THRESHOLD]\n",
    "        self._targets = torch.tensor(self.outcomes[\"label\"].values)\n",
    "\n",
    "    def load_relevant_segments(self, row):\n",
    "        identifier: str = row[\"identifier\"]\n",
    "        seq_start = row[\"start\"]\n",
    "        seq_end = row[\"end\"]\n",
    "        datetime_of_birth = row[\"datetime_of_birth\"]\n",
    "        segment_number = row[\"segment_number\"]\n",
    "\n",
    "        ctg_segment = pd.read_parquet(\n",
    "            self.data_dir\n",
    "            / \"ctgs\"\n",
    "            / \"filtered_segments\"\n",
    "            / f\"{identifier}_{segment_number}.parquet\"\n",
    "        )\n",
    "\n",
    "        # Select seq window, resample and impute\n",
    "        seq_ctg = ctg_segment[seq_start:seq_end]\n",
    "        if len(seq_ctg) > 2400:\n",
    "            seq_ctg = seq_ctg.head(2400)\n",
    "        if len(seq_ctg) < 2400:\n",
    "            adj_seq_start_actual = seq_ctg.index.min()\n",
    "            adj_seq_end_actual = seq_ctg.index.max()\n",
    "            if seq_start < adj_seq_start_actual:\n",
    "                seq_ctg = pd.concat([pd.DataFrame(index=[seq_start]), seq_ctg])\n",
    "            if seq_end > adj_seq_end_actual:\n",
    "                seq_ctg = pd.concat([seq_ctg, seq_ctg, pd.DataFrame(index=[seq_end])])\n",
    "            seq_ctg = seq_ctg.resample(\"0.25S\").agg({\"FHR1\": np.mean, \"TOCO\": np.mean})\n",
    "            seq_ctg[\"FHR1\"] = seq_ctg[\"FHR1\"].interpolate(method=\"linear\")\n",
    "            seq_ctg[\"TOCO\"] = seq_ctg[\"TOCO\"].interpolate(method=\"linear\")\n",
    "\n",
    "        FHR_segment = seq_ctg[\"FHR1\"].values.tolist()\n",
    "        TOCO_segment = seq_ctg[\"TOCO\"].values.tolist()\n",
    "\n",
    "        time_segment: List[datetime] = seq_ctg.index.tolist()\n",
    "        time_segment = [\n",
    "            (datetime_of_birth - index_time).total_seconds()\n",
    "            / MAX_DATETIME_DIFFERENCE_CTG.total_seconds()\n",
    "            for index_time in time_segment\n",
    "        ]\n",
    "        if len(FHR_segment) != 2400:\n",
    "            raise ValueError(\n",
    "                f\"FHR segment has length {len(FHR_segment)}, expected length 2400.\"\n",
    "            )\n",
    "\n",
    "        signal = torch.from_numpy(np.array([FHR_segment])).float()\n",
    "\n",
    "        return signal\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.outcomes.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        outcome = self.outcomes.iloc[index]\n",
    "        ctg_tensor = self.load_relevant_segments(outcome)\n",
    "        #         ctg_tensor = ctg_tensor.permute(1, 0)\n",
    "        label: int = outcome[\"label\"]\n",
    "        return ctg_tensor, label\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> Tensor:\n",
    "        return self._targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTGDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Datamodule class to load the CTG dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: Path = Path(\"../ctg-data/final-ctg-dataset/\"),\n",
    "        batch_size: int = 32,\n",
    "        split_seed: int = 50,\n",
    "        num_workers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        self.full_dataset = CTGDataset(\n",
    "            self.hparams.data_dir,\n",
    "        )\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            np.arange(len(self.full_dataset)),\n",
    "            test_size=0.1,\n",
    "            random_state=self.hparams.split_seed,\n",
    "            shuffle=True,\n",
    "            stratify=self.full_dataset.targets,\n",
    "        )\n",
    "        self.train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        self.data_test = Subset(self.full_dataset, test_idx)\n",
    "        self.train_targets = self.full_dataset.targets[train_idx]\n",
    "        self.test_targets = self.full_dataset.targets[test_idx]\n",
    "\n",
    "        train_indexes, val_indexes = train_test_split(\n",
    "            np.arange(len(self.train_dataset)),\n",
    "            test_size=0.25,\n",
    "            random_state=self.hparams.split_seed,\n",
    "            shuffle=True,\n",
    "            stratify=self.train_targets,\n",
    "        )\n",
    "\n",
    "        # Smaller dataset experiment\n",
    "        smaller_train_dataset_indexes = random.sample(\n",
    "            sorted(train_indexes), self.hparams.batch_size * 160\n",
    "        )\n",
    "        self.data_train_small = Subset(\n",
    "            self.train_dataset, smaller_train_dataset_indexes\n",
    "        )\n",
    "\n",
    "        smaller_val_dataset_indexes = random.sample(\n",
    "            sorted(val_indexes), self.hparams.batch_size * 10\n",
    "        )\n",
    "        self.data_val_small = Subset(self.train_dataset, smaller_val_dataset_indexes)\n",
    "\n",
    "        smaller_test_dataset_indexes = random.sample(\n",
    "            sorted(test_idx), self.hparams.batch_size * 10\n",
    "        )\n",
    "        self.data_test_small = Subset(self.full_dataset, smaller_test_dataset_indexes)\n",
    "\n",
    "        self.data_train = Subset(self.train_dataset, train_indexes)\n",
    "        self.data_val = Subset(self.train_dataset, val_indexes)\n",
    "\n",
    "        # Apply normalization to data\n",
    "        # Determine scaler based on training data\n",
    "        # Apply scaling based on training data to val\n",
    "        # Apply scaling based on training data to test\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_train_small,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_val_small,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.data_test_small,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CTGVAE(pl.LightningModule):\n",
    "    \"\"\"The class represneting the VAE model used for regression on CTGs.\"\"\"\n",
    "\n",
    "    def __init__(self, **hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        modules = []\n",
    "        hidden_dims = [32, 64, 128, 256, 512]\n",
    "        latent_dim = self.hparams.latent_size\n",
    "\n",
    "        # Build Encoder\n",
    "        in_channels = self.hparams.no_of_features\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=h_dim,\n",
    "                        kernel_size=6,\n",
    "                        stride=4,\n",
    "                        padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1] * 2, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1] * 2, latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 2)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose1d(\n",
    "                        hidden_dims[i],\n",
    "                        hidden_dims[i + 1],\n",
    "                        kernel_size=6,\n",
    "                        stride=4,\n",
    "                        padding=1,\n",
    "                        output_padding=1,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.ConvTranspose1d(\n",
    "                hidden_dims[-1],\n",
    "                hidden_dims[-1],\n",
    "                kernel_size=16,\n",
    "                stride=4,\n",
    "                padding=1,\n",
    "                output_padding=2,\n",
    "            ),\n",
    "            nn.BatchNorm1d(hidden_dims[-1]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(\n",
    "                hidden_dims[-1],\n",
    "                out_channels=self.hparams.no_of_features,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def reparametize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            noise = torch.randn_like(std)\n",
    "            z = mu + noise * std\n",
    "            return z\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode input space to hidden space\n",
    "        enc = self.encoder(x)\n",
    "        enc = torch.flatten(enc, start_dim=1)\n",
    "\n",
    "        # extract latent variable z(hidden space to latent space)\n",
    "        mean = self.fc_mu(enc)\n",
    "        logvar = self.fc_var(enc)\n",
    "\n",
    "        z = self.reparametize(mean, logvar)  # batch_size x latent_size\n",
    "\n",
    "        # decode latent space to input space\n",
    "        z = self.decoder_input(z)\n",
    "        z = z.view(-1, 512, 2)\n",
    "        out = self.decoder(z)\n",
    "        x_hat = self.final_layer(out)\n",
    "\n",
    "        return mean, logvar, x_hat\n",
    "\n",
    "    def loss_function(self, x_hat, x, mu, log_var) -> dict:\n",
    "        # recons_loss = F.smooth_l1_loss(x_hat, x, reduction='mean')\n",
    "        # kld_loss = -0.5 * torch.mean(1 + log_var - mu ** 2 - log_var.exp())\n",
    "\n",
    "        if self.training:\n",
    "            recons_loss = torch.sum(\n",
    "                torch.sum(F.mse_loss(x_hat, x, reduction=\"none\"), dim=(1, 2))\n",
    "            )\n",
    "        else:\n",
    "            recons_loss = torch.mean(\n",
    "                torch.sum(F.mse_loss(x_hat, x, reduction=\"none\"), dim=(1, 2))\n",
    "            )\n",
    "\n",
    "        if self.training:\n",
    "            kld_loss = torch.sum(\n",
    "                -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n",
    "            )\n",
    "        else:\n",
    "            kld_loss = torch.mean(\n",
    "                -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n",
    "            )\n",
    "\n",
    "        # To account for minibatches\n",
    "        batch_weight = x.shape[0] / self.hparams.batch_size\n",
    "        kld_weight = self.get_cyclic_kl_annealing_weight()\n",
    "\n",
    "        loss = (recons_loss + (kld_weight * kld_loss)) * batch_weight\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"recon_loss\": recons_loss,\n",
    "            \"kld\": -kld_loss,\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "            eps=1e-4,\n",
    "        )\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            opt, T_0=25, T_mult=1, eta_min=1e-9, last_epoch=-1\n",
    "        )\n",
    "        return [opt], [sch]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_hat = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_hat, x, mu, log_var)\n",
    "        loss_dict = self.loss_function(x_hat, x, mu, log_var)\n",
    "        self.calculate_and_log_metrics(loss_dict, \"train\", self.hparams.batch_size)\n",
    "        return loss_dict\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        self.calculate_and_log_metrics(loss_dict, \"val\", self.hparams.batch_size)\n",
    "        if batch_idx == 0:\n",
    "            self.plots_path = data_dir / \"..\" / \"..\" / \"plots\"\n",
    "            self.plots_path.mkdir(exist_ok=True)\n",
    "            if (self.current_epoch == 0) or (\n",
    "                not (self.plots_path / \"original_fhr.png\").exists()\n",
    "            ):\n",
    "                orig_saved_filename = self.save_signal_figure(x[0], \"original_fhr\", 0)\n",
    "                self.logger.experiment.log_artifact(\n",
    "                    self.logger.run_id, orig_saved_filename\n",
    "                )\n",
    "            recon_saved_filename = self.save_signal_figure(\n",
    "                x_out[0], \"reconstructed_fhr\", 0\n",
    "            )\n",
    "            self.logger.experiment.log_artifact(\n",
    "                self.logger.run_id, recon_saved_filename\n",
    "            )\n",
    "        return loss_dict\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        mu, log_var, x_out = self.forward(x)\n",
    "        loss_dict = self.loss_function(x_out, x, mu, log_var)\n",
    "        self.calculate_and_log_metrics(loss_dict, \"val\", self.hparams.batch_size)\n",
    "        return loss_dict\n",
    "\n",
    "    def calculate_and_log_metrics(self, loss_dict, step_type, batch_size):\n",
    "        self.log(\n",
    "            f\"kld_weight\",\n",
    "            self.get_cyclic_kl_annealing_weight(),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{step_type}_loss\",\n",
    "            loss_dict[\"loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{step_type}_kld_loss\",\n",
    "            loss_dict[\"kld\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{step_type}_recon_loss\",\n",
    "            loss_dict[\"recon_loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "    def save_signal_figure(self, signal_tensor, name, signal_dim):\n",
    "        fhr_tensor = signal_tensor[signal_dim].cpu().detach().numpy()\n",
    "        # toco_tensor = signal_tensor[1].cpu().detach().numpy()\n",
    "        output_df = pd.DataFrame.from_dict({\"FHR1\": fhr_tensor})\n",
    "        fig = visualize_ctg(ctg=output_df, toco_present=False)\n",
    "\n",
    "        if \"original\" in name:\n",
    "            saved_filename = f\"{name}.png\"\n",
    "        else:\n",
    "            saved_filename = f\"{name}_epoch_{self.current_epoch+1}.png\"\n",
    "\n",
    "        saved_filepath = self.plots_path / saved_filename\n",
    "        fig.write_image(saved_filepath)\n",
    "        return saved_filepath\n",
    "\n",
    "    def get_monotonic_kl_annealing_weight(self):\n",
    "        if (self.current_epoch + 1) > self.hparams.kl_annealing_epoch:\n",
    "            return 1\n",
    "        else:\n",
    "            return (self.current_epoch + 1) / (self.hparams.kl_annealing_epoch)\n",
    "\n",
    "    def get_cyclic_kl_annealing_weight(self):\n",
    "        current_epoch = self.current_epoch\n",
    "        kl_annealing_epoch = self.hparams.kl_annealing_epoch\n",
    "        is_annealing_step: bool = (\n",
    "            math.ceil((current_epoch + 1) / (kl_annealing_epoch)) % 2 != 0\n",
    "        ) and ((current_epoch + 1) % kl_annealing_epoch != 0)\n",
    "        if is_annealing_step:\n",
    "            return (current_epoch + 1) % (kl_annealing_epoch) / (kl_annealing_epoch)\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(\n",
    "    hparams: OrderedDict,\n",
    "    datamodule: pl.LightningDataModule,\n",
    "    ckpt_path: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Train the CTGCNN model given the hyperparameters as config and the number of epochs.\n",
    "    The tune flag is used to specify if the training is standalone or part of a hyperparameter optimization process.\n",
    "    The k_fold flag is used to specify if the training should be done as K fold cross validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Clear out the previous models\n",
    "    models_folder = Path(f\"../models/\")\n",
    "\n",
    "    shutil.rmtree(models_folder)\n",
    "    models_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    mlflow_runs_folder = Path(\"../mlruns\")\n",
    "    mlflow_runs_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    val_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=models_folder,\n",
    "        filename=\"models-{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\",\n",
    "        save_on_train_epoch_end=True,\n",
    "    )\n",
    "\n",
    "    periodic_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=models_folder,\n",
    "        filename=\"models-{epoch:02d}-{val_loss:.2f}\",\n",
    "        every_n_epochs=10,\n",
    "    )\n",
    "\n",
    "    # early_stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "\n",
    "    callbacks.append(val_checkpoint_callback)\n",
    "    callbacks.append(periodic_checkpoint_callback)\n",
    "    # callbacks.append(early_stopping_callback)\n",
    "\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=\"ctg_vae_cnn\",\n",
    "        tracking_uri=mlflow_runs_folder.absolute().as_uri(),\n",
    "    )\n",
    "    ctg_cnn_model = CTGVAE(**hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        logger=mlf_logger,\n",
    "        max_epochs=hparams[\"num_epochs\"],\n",
    "        callbacks=callbacks,\n",
    "        num_sanity_val_steps=0,\n",
    "        devices=1,\n",
    "        # strategy=\"ddp_notebook\",\n",
    "    )\n",
    "    trainer.fit(model=ctg_cnn_model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
    "    trainer.test(model=ctg_cnn_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "hparams = OrderedDict(\n",
    "    beta=0,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    no_of_features=1,\n",
    "    latent_size=24,\n",
    "    batch_size=256,\n",
    ")\n",
    "model = CTGVAE(**hparams)\n",
    "summary(model, input_size=(128, 1, 2400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try training the model with some hyperparameters.\n",
    "ctg_datamodule = CTGDataModule(\n",
    "    data_dir=Path(\"/mnt/ssd2/ctg-analysis/ctg-data/final-ctg-dataset/\"),\n",
    "    split_seed=SEED_VALUE,\n",
    "    num_workers=16,\n",
    "    batch_size=256,\n",
    ")\n",
    "ctg_datamodule.prepare_data()\n",
    "ctg_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try training the model with some hyperparameters.\n",
    "hparams = OrderedDict(\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    no_of_features=1,\n",
    "    latent_size=24,\n",
    "    batch_size=128,\n",
    "    kl_annealing_epoch=10,\n",
    "    num_epochs=101,\n",
    ")\n",
    "train_model_with_hyperparams(\n",
    "    hparams=hparams,\n",
    "    datamodule=ctg_datamodule,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3eea0ff59f7088be88745afe0c6118fe13decd50e4eb2ccdeb922a8509f15427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
